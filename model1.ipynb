{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tashaphyne in /home/ahmed/.local/lib/python3.10/site-packages (0.3.6)\n",
      "Requirement already satisfied: pyarabic in /home/ahmed/.local/lib/python3.10/site-packages (from tashaphyne) (0.6.15)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from pyarabic->tashaphyne) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarabic in /home/ahmed/.local/lib/python3.10/site-packages (0.6.15)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from pyarabic) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in /home/ahmed/.local/lib/python3.10/site-packages (1.7.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ahmed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ahmed/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string                             \n",
    "\n",
    "!pip install tashaphyne\n",
    "import tashaphyne\n",
    "from tashaphyne.stemming import ArabicLightStemmer\n",
    "\n",
    "!pip install pyarabic\n",
    "import pyarabic\n",
    "\n",
    "!pip install emoji\n",
    "import emoji\n",
    "\n",
    "import nltk                             \n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')                                \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "df = pd.read_csv('Dataset/train.csv', encoding='UTF-8')\n",
    "tweets = df['text']\n",
    "categories = df['category']\n",
    "stances = df['stance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArListem = ArabicLightStemmer()\n",
    "\n",
    "def stem_tweet(tweet_tokens):\n",
    "    for i in range(len(tweet_tokens)):\n",
    "        ArListem.light_stem(tweet_tokens[i])\n",
    "        tweet_tokens[i] = ArListem.get_root()\n",
    "    return tweet_tokens\n",
    "\n",
    "def remove_url(tweet):\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    return tweet\n",
    "\n",
    "def remove_retweet_tag(tweet):\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def remove_tweet_mentions(tweet):\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def remove_text_control_tags(tweet):\n",
    "    tweet = re.sub(r'\\n|\\t|\\r|<LF>|<lf>', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def tokenize_tweet(tweet):\n",
    "    tweet_tokens = re.split(', |_|-|!', tweet)\n",
    "    return tweet_tokens\n",
    "\n",
    "def remove_stopwords_punctuation(tweet_tokens, stop_words = ()):\n",
    "    tweet_reduced = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stop_words and word not in string.punctuation):\n",
    "            tweet_reduced.append(word)\n",
    "            tweet_reduced[-1] = re.sub(r'[~`!@#$%^&*()-_+={}[\\]|/\\:;\"`<>,.?؟،]+', '', tweet_reduced[-1])\n",
    "    return tweet_reduced\n",
    "\n",
    "def remove_specialcharacters(tweet):\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def handle_emojis(tweet):\n",
    "    tweet = emoji.demojize(tweet, language='en') # convert emojis to text ENGLISH!!\n",
    "    return tweet\n",
    "\n",
    "def normalize_tweet(tweet_tokens):\n",
    "    for i in range(len(tweet_tokens)):\n",
    "        tweet_tokens[i] = pyarabic.araby.strip_tashkeel(tweet_tokens[i])\n",
    "        tweet_tokens[i] = pyarabic.araby.strip_tatweel(tweet_tokens[i])\n",
    "        tweet_tokens[i] = pyarabic.araby.strip_lastharaka(tweet_tokens[i])\n",
    "        tweet_tokens[i] = pyarabic.araby.normalize_alef(tweet_tokens[i])\n",
    "        tweet_tokens[i] = re.sub(r'(.)\\1{3,}', r\"\\1\\1\\1\", tweet_tokens[i]) # Remove longation\n",
    "        tweet_tokens[i] = pyarabic.araby.normalize_hamza(tweet_tokens[i])\n",
    "    return tweet_tokens\n",
    "\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = remove_url(tweet)\n",
    "    tweet = remove_retweet_tag(tweet)\n",
    "    tweet = remove_tweet_mentions(tweet)\n",
    "    tweet = remove_specialcharacters(tweet)\n",
    "    tweet = remove_text_control_tags(tweet)\n",
    "    tweet = handle_emojis(tweet)\n",
    "    tweet_tokens = tokenize_tweet(tweet)\n",
    "    tweet_tokens = normalize_tweet(tweet_tokens)\n",
    "    tweet_tokens_reduced = remove_stopwords_punctuation(tweet_tokens, stopwords.words('arabic'))\n",
    "    # tweet_tokens_stemmed = stem_tweet(tweet_tokens_reduced)\n",
    "    tweet = ' '.join(tweet_tokens_reduced)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
